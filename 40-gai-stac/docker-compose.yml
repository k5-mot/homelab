name: ${HOMELAB_NAME}-llm-stack

services:

  # nginx:
  #   image: docker.io/nginx:1.27.1
  #   container_name: ${HOMELAB_NAME}-nginx
  #   restart: always
  #   ports:
  #     - 80:80
  #     - 443:443
  #   env_file:
  #     - ../base.env
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #   networks:
  #     - network-reverse-proxy

  # https://github.com/ollama/ollama/blob/main/docs/docker.md
  ollama:
    build:
      context: ./ollama
      dockerfile: ./Dockerfile
      args:
        - HTTP_PROXY=${PROXY_ADDRESS}
        - HTTPS_PROXY=${PROXY_ADDRESS}
    container_name: ${HOMELAB_NAME}-ollama
    restart: unless-stopped
    volumes:
      - volume-ollama:/root/.ollama
      - volume-ollama-build:/workspace
    networks:
      - network-reverse-proxy
      - network-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  # https://github.com/Unstructured-IO/unstructured-api
  unstructured:
    image: downloads.unstructured.io/unstructured-io/unstructured-api:latest
    container_name: ${HOMELAB_NAME}-unstructured
    restart: unless-stopped
    environment:
      - PORT=9500
    networks:
      - network-reverse-proxy

  crontab:
    build:
      context: ./crontab
      dockerfile: ./Dockerfile
      args:
        - HTTP_PROXY=${PROXY_ADDRESS}
        - HTTPS_PROXY=${PROXY_ADDRESS}
    container_name: ${HOMELAB_NAME}-crontab
    restart: always
    volumes:
      - ./docs:/docs:ro
      - ./:/workspaces:cached
    networks:
      - network-reverse-proxy

  langserve:
    build:
      context: ./langserve
      dockerfile: ./Dockerfile
      args:
        - HTTP_PROXY=${PROXY_ADDRESS}
        - HTTPS_PROXY=${PROXY_ADDRESS}
    container_name: ${HOMELAB_NAME}-langserve
    restart: always
    ports:
      - 31000:8000
    volumes:
      - ./docs:/docs:ro
    networks:
      - network-reverse-proxy

  # https://docs.chainlit.io/authentication/oauth#gitlab
  chainlit:
    build:
      context: ./chainlit
      dockerfile: ./Dockerfile
      args:
        - HTTP_PROXY=${PROXY_ADDRESS}
        - HTTPS_PROXY=${PROXY_ADDRESS}
    container_name: ${HOMELAB_NAME}-chainlit
    restart: always
    environment:
      # - OAUTH_GITLAB_CLIENT_ID=""
      # - OAUTH_GITLAB_CLIENT_SECRET=""
      # - OAUTH_GITLAB_DOMAIN=""
      - HTTP_PROXY=${PROXY_ADDRESS}
      - HTTPS_PROXY=${PROXY_ADDRESS}
    volumes:
      - ./docs:/docs:ro
    networks:
      - network-reverse-proxy

  chroma:
    image: chromadb/chroma:0.5.11
    container_name: ${HOMELAB_NAME}-chroma
    restart: always
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma # this is the default path, change it as needed
      - ANONYMIZED_TELEMETRY=FALSE
    volumes:
      - volume-chroma:/chroma/chroma
    networks:
      - network-reverse-proxy

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    container_name: ${HOMELAB_NAME}-elasticsearch
    restart: always
    shm_size: 1g
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - "ES_JAVA_OPTS=-Xms1024m -Xmx1024m"
    volumes:
      - volume-elasticsearch:/usr/share/elasticsearch/data
    networks:
      - network-reverse-proxy

  jupyterhub:
    build:
      context: ./jupyterhub
      dockerfile: ./Dockerfile
      args:
        - HTTP_PROXY=${PROXY_ADDRESS}
        - HTTPS_PROXY=${PROXY_ADDRESS}
    container_name: ${HOMELAB_NAME}-jupyterhub
    restart: unless-stopped
    env_file:
      - ../base.env
    environment:
      # - GITLAB_HOST=${GITLAB_HOST}
      # - OAUTH_CALLBACK_URL=${OAUTH_CALLBACK_URL}
      # - GITLAB_CLIENT_ID=${GITLAB_CLIENT_ID}
      # - GITLAB_CLIENT_SECRET=${GITLAB_CLIENT_SECRET}
      - HTTP_PROXY=${PROXY_ADDRESS}
      - HTTPS_PROXY=${PROXY_ADDRESS}
    networks:
      - network-reverse-proxy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
  # nni:
  #   image: docker.io/msranni/nni:latest
  #   container_name: ${HOMELAB_NAME}-nni
  #   restart: unless-stopped
  #   env_file:
  #     - ../base.env
  #     - .env

  # https://docs.langflow.org/deployment-docker
  # langflow:
  #   image: docker.io/langflowai/langflow:latest
  #   container_name: ${HOMELAB_NAME}-langflow
  #   restart: unless-stopped
  #   ports:
  #     - 30111:7860
  #   env_file:
  #     - ../base.env
  #   environment:
  #     - LANGFLOW_DATABASE_URL=postgresql://langflow_user:langflow_pass@langflow-db:5432/langflow_base
  #     - LANGFLOW_STORE_ENVIRONMENT_VARIABLES=true
  #   volumes:
  #     - volume-langflow:/app/langflow
  #   networks:
  #     - network-langflow
  #   depends_on:
  #     - langflow-db

  # langflow-db:
  #   image: docker.io/postgres:16
  #   container_name: ${HOMELAB_NAME}-langflow-db
  #   restart: unless-stopped
  #   env_file:
  #     - ../base.env
  #   environment:
  #     POSTGRES_USER: langflow_user
  #     POSTGRES_PASSWORD: langflow_pass
  #     POSTGRES_DB: langflow_base
  #   volumes:
  #     - volume-langflow-db:/var/lib/postgresql/data
  #   networks:
  #     - network-langflow
  #   healthcheck:
  #     test: [ "CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB} || exit 1" ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 5s


  langfuse:
    image: langfuse/langfuse:2
    container_name: ${HOMELAB_NAME}-langfuse
    depends_on:
      langfuse-db:
        condition: service_healthy
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@langfuse-db:5432/postgres
      - NEXTAUTH_SECRET=mysecret
      - SALT=mysalt
      - ENCRYPTION_KEY=0000000000000000000000000000000000000000000000000000000000000000 # generate via `openssl rand -hex 32`
      - NEXT_PUBLIC_BASE_PATH=/langfuse
      - NEXTAUTH_URL="http://localhost:3000/langfuse/api/auth"
      - TELEMETRY_ENABLED=false
      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=false
      - LANGFUSE_INIT_ORG_ID=${HOMELAB_NAME}-org
      - LANGFUSE_INIT_ORG_NAME=${HOMELAB_NAME}-org
      - LANGFUSE_INIT_PROJECT_ID=initial-project
      - LANGFUSE_INIT_PROJECT_NAME=initial-project
      - LANGFUSE_INIT_PROJECT_PUBLIC_KEY=lf_pk_1234567890
      - LANGFUSE_INIT_PROJECT_SECRET_KEY=lf_sk_1234567890
      - LANGFUSE_INIT_USER_EMAIL=user@example.com
      - LANGFUSE_INIT_USER_NAME=John Doe
      - LANGFUSE_INIT_USER_PASSWORD=password123

  langfuse-db:
    image: postgres
    container_name: ${HOMELAB_NAME}-langfuse-db
    restart: always
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 3s
      timeout: 3s
      retries: 10
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
    ports:
      - 5432:5432
    volumes:
      - volume-langfuse-db:/var/lib/postgresql/data

networks:
  network-reverse-proxy:
    name: ${HOMELAB_NAME}-network-reverse-proxy
    external: true
  network-ollama:
    name: ${HOMELAB_NAME}-network-ollama
  network-langflow:
    name: ${HOMELAB_NAME}-network-langflow

volumes:
  volume-ollama:
    name: ${HOMELAB_NAME}-volume-ollama
  volume-ollama-build:
    name: ${HOMELAB_NAME}-volume-ollama-build
  volume-langflow:
    name: ${HOMELAB_NAME}-volume-langflow
  volume-langflow-db:
    name: ${HOMELAB_NAME}-volume-langflow-db
  volume-chroma:
    name: ${HOMELAB_NAME}-volume-chroma
  volume-elasticsearch:
    name: ${HOMELAB_NAME}-volume-elasticsearch
  volume-langfuse-db:
    name: ${HOMELAB_NAME}-volume-langfuse-db
