name: homelab-llm-stack

services:

  ollama:
    image: docker.io/ollama/ollama:latest
    container_name: homelab-ollama
    # pull_policy: always
    tty: true
    # runtime: nvidia
    restart: unless-stopped
    env_file:
      - ../proxy.env
    environment:
      - OLLAMA_HOST=0.0.0.0
    ports:
      - 11434:11434
    volumes:
      - ./ollama:/root/ollama
      - volume-ollama:/root/.ollama
    networks:
      - network-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: homelab-open-webui
    restart: unless-stopped
    env_file:
      - ../proxy.env
      - ./litellm/litellm.env
    depends_on:
      - ollama
    extra_hosts:
      - host.docker.internal:host-gateway
    ports:
      - 30015:8080
    environment:
      - OLLAMA_BASE_URL=http://192.168.11.13:11434
      - OPENAI_API_BASE_URL=http://192.168.11.13:4000/v1;http://192.168.11.13:9099
      - OPENAI_API_KEY=${LITELLM_API_KEY};0p3n-w3bu!
      # - WEBUI_SECRET_KEY=
      - WEBUI_AUTH=False
    volumes:
      - volume-open-webui:/app/backend/data
    networks:
      - network-ollama

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: homelab-pipelines
    restart: always
    env_file:
      - ../proxy.env
    extra_hosts:
      - host.docker.internal:host-gateway
    ports:
      - 9099:9099
    volumes:
      - volume-pipelines:/app/pipelines
    networks:
      - network-ollama

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: homelab-litellm
    env_file:
      - ../proxy.env
      - ./litellm/litellm.env
    environment:
      - MASTER_KEY=${LITELLM_API_KEY}
    ports:
      - 4000:8000
    volumes:
      - ./litellm/config.yaml:/app/config.yaml
    command: [ "--config", "/app/config.yaml", "--port", "8000" ]
    restart: unless-stopped
    networks:
      - network-ollama

  langflow:
    image: docker.io/langflowai/langflow:latest
    container_name: homelab-langflow
    env_file:
      - ../proxy.env
      - ./litellm/litellm.env
    ports:
      - 7860:7860
    depends_on:
      - langflow-db
    environment:
      - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow@langflow-db:5432/langflow
    volumes:
      - volume-langflow:/app/langflow
    networks:
      - network-langflow

  langflow-db:
    image: docker.io/postgres:16
    container_name: homelab-langflow-db
    env_file:
      - ../noproxy.env
    environment:
      POSTGRES_USER: langflow
      POSTGRES_PASSWORD: langflow
      POSTGRES_DB: langflow
    ports:
      - 5432:5432
    volumes:
      - volume-langflow-db:/var/lib/postgresql/data
    networks:
      - network-langflow


  flowise:
    image: docker.io/flowiseai/flowise
    container_name: homelab-flowise
    restart: always
    env_file:
      - ../proxy.env
      - ./flowise/flowise.env
    # environment:
    #   # - PORT=${PORT}
    #   - CORS_ORIGINS=${CORS_ORIGINS}
    #   - IFRAME_ORIGINS=${IFRAME_ORIGINS}
    #   - FLOWISE_USERNAME=${FLOWISE_USERNAME}
    #   - FLOWISE_PASSWORD=${FLOWISE_PASSWORD}
    #   - FLOWISE_FILE_SIZE_LIMIT=${FLOWISE_FILE_SIZE_LIMIT}
    #   - DEBUG=${DEBUG}
    #   # - DATABASE_PATH=${DATABASE_PATH}
    #   - DATABASE_TYPE=${DATABASE_TYPE}
    #   - DATABASE_PORT=${DATABASE_PORT}
    #   - DATABASE_HOST=${DATABASE_HOST}
    #   - DATABASE_NAME=${DATABASE_NAME}
    #   - DATABASE_USER=${DATABASE_USER}
    #   - DATABASE_PASSWORD=${DATABASE_PASSWORD}
    #   - DATABASE_SSL=${DATABASE_SSL}
    #   - DATABASE_SSL_KEY_BASE64=${DATABASE_SSL_KEY_BASE64}
    #   # - APIKEY_PATH=${APIKEY_PATH}
    #   # - SECRETKEY_PATH=${SECRETKEY_PATH}
    #   - FLOWISE_SECRETKEY_OVERWRITE=${FLOWISE_SECRETKEY_OVERWRITE}
    #   - LOG_LEVEL=${LOG_LEVEL}
    #   # - LOG_PATH=${LOG_PATH}
    #   # - BLOB_STORAGE_PATH=${BLOB_STORAGE_PATH}
    #   - DISABLE_FLOWISE_TELEMETRY=${DISABLE_FLOWISE_TELEMETRY}
    #   - MODEL_LIST_CONFIG_JSON=${MODEL_LIST_CONFIG_JSON}
    ports:
      - '${PORT:-3000}:${PORT:-3000}'
    volumes:
      - ~/.flowise:/root/.flowise
    entrypoint: /bin/sh -c "sleep 3; flowise start"


networks:
  # network-reverse-proxy:
  #   external: true
  network-ollama:
    name: homelab-network-ollama
  network-langflow:
    name: homelab-network-langflow

volumes:
  volume-ollama:
    name: homelab-volume-ollama
  volume-open-webui:
    name: homelab-volume-open-webui
  volume-pipelines:
    name: homelab-volume-pipelines
  volume-langflow:
    name: homelab-volume-langflow
  volume-langflow-db:
    name: homelab-volume-langflow-db
